{"cells":[{"cell_type":"code","execution_count":null,"id":"MA9zKlDQoXw-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3373,"status":"ok","timestamp":1673169915544,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"MA9zKlDQoXw-","outputId":"039eb502-0713-477a-ebe5-952ef23bda34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"id":"YaWQCuHxotpw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673169917999,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"YaWQCuHxotpw","outputId":"b4fb3f62-516d-482c-84ef-f32df75cdb61"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/Modified-IRNet\n"]}],"source":["cd '/content/gdrive/MyDrive/Colab Notebooks/Modified-IRNet'"]},{"cell_type":"code","execution_count":null,"id":"0cspDVjkowrB","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673169919742,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"0cspDVjkowrB","outputId":"74c078d7-cab7-45fa-c273-9ccac1dceebc"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4') ##Required for Colab"]},{"cell_type":"code","execution_count":null,"id":"C1fuRc6Qo4f_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3153,"status":"ok","timestamp":1673169924923,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"C1fuRc6Qo4f_","outputId":"ecb537ce-59d9-4a9a-809f-6d5cb78941ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pattern in /usr/local/lib/python3.8/dist-packages (3.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pattern) (0.16.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from pattern) (4.9.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pattern) (1.7.3)\n","Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.8/dist-packages (from pattern) (20221105)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pattern) (2.25.1)\n","Requirement already satisfied: mysqlclient in /usr/local/lib/python3.8/dist-packages (from pattern) (2.1.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pattern) (3.7)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.8/dist-packages (from pattern) (0.8.11)\n","Requirement already satisfied: backports.csv in /usr/local/lib/python3.8/dist-packages (from pattern) (1.0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pattern) (1.21.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from pattern) (4.6.3)\n","Requirement already satisfied: feedparser in /usr/local/lib/python3.8/dist-packages (from pattern) (6.0.10)\n","Requirement already satisfied: cherrypy in /usr/local/lib/python3.8/dist-packages (from pattern) (18.8.0)\n","Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (2.0)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (9.0.0)\n","Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (3.1.0)\n","Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (9.0.0)\n","Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (3.8.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.8/dist-packages (from feedparser->pattern) (1.0.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (4.64.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (1.2.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six->pattern) (39.0.0)\n","Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six->pattern) (2.1.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (2022.12.7)\n","Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.8/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (3.5.2)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n","Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.8/dist-packages (from portend>=2.1.1->cherrypy->pattern) (5.2.0)\n","Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.8/dist-packages (from jaraco.collections->cherrypy->pattern) (3.2.3)\n","Requirement already satisfied: jaraco.text in /usr/local/lib/python3.8/dist-packages (from jaraco.collections->cherrypy->pattern) (3.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.7)\n","Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (4.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.10.1)\n","Requirement already satisfied: autocommand in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.2.2)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.1.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.11.0)\n"]}],"source":["pip install pattern"]},{"cell_type":"code","execution_count":null,"id":"c714c0ff","metadata":{"id":"c714c0ff"},"outputs":[],"source":["import argparse\n","import traceback\n","\n","from src.rule.graph import Graph\n","from src.rule.semQL import Sup, Sel, Order, Root, Filter, A, N, C, T, Root1\n","from src.rule.sem_utils import alter_inter, alter_not_in, alter_column0, load_dataSets"]},{"cell_type":"code","execution_count":null,"id":"9f46a4ca","metadata":{"id":"9f46a4ca"},"outputs":[],"source":["## Code copied from IRNET\n","def split_logical_form(lf):\n","    indexs = [i+1 for i, letter in enumerate(lf) if letter == ')']\n","    indexs.insert(0, 0)\n","    components = list()\n","    for i in range(1, len(indexs)):\n","        components.append(lf[indexs[i-1]:indexs[i]].strip())\n","    return components\n","\n","\n","def pop_front(array):\n","    if len(array) == 0:\n","        return 'None'\n","    return array.pop(0)\n","\n","\n","def is_end(components, transformed_sql, is_root_processed):\n","    end = False\n","    c = pop_front(components)\n","    c_instance = eval(c)\n","\n","    if isinstance(c_instance, Root) and is_root_processed:\n","        # intersect, union, except\n","        end = True\n","    elif isinstance(c_instance, Filter):\n","        if 'where' not in transformed_sql:\n","            end = True\n","        else:\n","            num_conjunction = 0\n","            for f in transformed_sql['where']:\n","                if isinstance(f, str) and (f == 'and' or f == 'or'):\n","                    num_conjunction += 1\n","            current_filters = len(transformed_sql['where'])\n","            valid_filters = current_filters - num_conjunction\n","            if valid_filters >= num_conjunction + 1:\n","                end = True\n","    elif isinstance(c_instance, Order):\n","        if 'order' not in transformed_sql:\n","            end = True\n","        elif len(transformed_sql['order']) == 0:\n","            end = False\n","        else:\n","            end = True\n","    elif isinstance(c_instance, Sup):\n","        if 'sup' not in transformed_sql:\n","            end = True\n","        elif len(transformed_sql['sup']) == 0:\n","            end = False\n","        else:\n","            end = True\n","    components.insert(0, c)\n","    return end\n","\n","\n","def _transform(components, transformed_sql, col_set, table_names, schema):\n","    processed_root = False\n","    current_table = schema\n","\n","    while len(components) > 0:\n","        if is_end(components, transformed_sql, processed_root):\n","            break\n","        c = pop_front(components)\n","        c_instance = eval(c)\n","        if isinstance(c_instance, Root):\n","            processed_root = True\n","            transformed_sql['select'] = list()\n","            if c_instance.id_c == 0:\n","                transformed_sql['where'] = list()\n","                transformed_sql['sup'] = list()\n","            elif c_instance.id_c == 1:\n","                transformed_sql['where'] = list()\n","                transformed_sql['order'] = list()\n","            elif c_instance.id_c == 2:\n","                transformed_sql['sup'] = list()\n","            elif c_instance.id_c == 3:\n","                transformed_sql['where'] = list()\n","            elif c_instance.id_c == 4:\n","                transformed_sql['order'] = list()\n","        elif isinstance(c_instance, Sel):\n","            continue\n","        elif isinstance(c_instance, N):\n","            for i in range(c_instance.id_c + 1):\n","                agg = eval(pop_front(components))\n","                column = eval(pop_front(components))\n","                _table = pop_front(components)\n","                table = eval(_table)\n","                if not isinstance(table, T):\n","                    table = None\n","                    components.insert(0, _table)\n","                assert isinstance(agg, A) and isinstance(column, C)\n","\n","                transformed_sql['select'].append((\n","                    agg.production.split()[1],\n","                    replace_col_with_original_col(col_set[column.id_c], table_names[table.id_c], current_table) if table is not None else col_set[column.id_c],\n","                    table_names[table.id_c] if table is not None else table\n","                ))\n","\n","        elif isinstance(c_instance, Sup):\n","            transformed_sql['sup'].append(c_instance.production.split()[1])\n","            agg = eval(pop_front(components))\n","            column = eval(pop_front(components))\n","            _table = pop_front(components)\n","            table = eval(_table)\n","            if not isinstance(table, T):\n","                table = None\n","                components.insert(0, _table)\n","            assert isinstance(agg, A) and isinstance(column, C)\n","\n","            transformed_sql['sup'].append(agg.production.split()[1])\n","            if table:\n","                fix_col_id = replace_col_with_original_col(col_set[column.id_c], table_names[table.id_c], current_table)\n","            else:\n","                fix_col_id = col_set[column.id_c]\n","                raise RuntimeError('not found table !!!!')\n","            transformed_sql['sup'].append(fix_col_id)\n","            transformed_sql['sup'].append(table_names[table.id_c] if table is not None else table)\n","\n","        elif isinstance(c_instance, Order):\n","            transformed_sql['order'].append(c_instance.production.split()[1])\n","            agg = eval(pop_front(components))\n","            column = eval(pop_front(components))\n","            _table = pop_front(components)\n","            table = eval(_table)\n","            if not isinstance(table, T):\n","                table = None\n","                components.insert(0, _table)\n","            assert isinstance(agg, A) and isinstance(column, C)\n","            transformed_sql['order'].append(agg.production.split()[1])\n","            transformed_sql['order'].append(replace_col_with_original_col(col_set[column.id_c], table_names[table.id_c], current_table))\n","            transformed_sql['order'].append(table_names[table.id_c] if table is not None else table)\n","\n","        elif isinstance(c_instance, Filter):\n","            op = c_instance.production.split()[1]\n","            if op == 'and' or op == 'or':\n","                transformed_sql['where'].append(op)\n","            else:\n","                # No Supquery\n","                agg = eval(pop_front(components))\n","                column = eval(pop_front(components))\n","                _table = pop_front(components)\n","                table = eval(_table)\n","                if not isinstance(table, T):\n","                    table = None\n","                    components.insert(0, _table)\n","                assert isinstance(agg, A) and isinstance(column, C)\n","                if len(c_instance.production.split()) == 3:\n","                    if table:\n","                        fix_col_id = replace_col_with_original_col(col_set[column.id_c], table_names[table.id_c], current_table)\n","                    else:\n","                        fix_col_id = col_set[column.id_c]\n","                        raise RuntimeError('not found table !!!!')\n","                    transformed_sql['where'].append((\n","                        op,\n","                        agg.production.split()[1],\n","                        fix_col_id,\n","                        table_names[table.id_c] if table is not None else table,\n","                        None\n","                    ))\n","                else:\n","                    # Subquery\n","                    new_dict = dict()\n","                    new_dict['sql'] = transformed_sql['sql']\n","                    transformed_sql['where'].append((\n","                        op,\n","                        agg.production.split()[1],\n","                        replace_col_with_original_col(col_set[column.id_c], table_names[table.id_c], current_table),\n","                        table_names[table.id_c] if table is not None else table,\n","                        _transform(components, new_dict, col_set, table_names, schema)\n","                    ))\n","\n","    return transformed_sql\n","\n","\n","def transform(query, schema, origin=None):\n","    preprocess_schema(schema)\n","    if origin is None:\n","        lf = query['model_result_replace']\n","    else:\n","        lf = origin\n","    # lf = query['rule_label']\n","    col_set = query['col_set']\n","    table_names = query['table_names']\n","    current_table = schema\n","\n","    current_table['schema_content_clean'] = [x[1] for x in current_table['column_names']]\n","    current_table['schema_content'] = [x[1] for x in current_table['column_names_original']]\n","\n","    components = split_logical_form(lf)\n","\n","    transformed_sql = dict()\n","    transformed_sql['sql'] = query\n","    c = pop_front(components)\n","    c_instance = eval(c)\n","    assert isinstance(c_instance, Root1)\n","    if c_instance.id_c == 0:\n","        transformed_sql['intersect'] = dict()\n","        transformed_sql['intersect']['sql'] = query\n","\n","        _transform(components, transformed_sql, col_set, table_names, schema)\n","        _transform(components, transformed_sql['intersect'], col_set, table_names, schema)\n","    elif c_instance.id_c == 1:\n","        transformed_sql['union'] = dict()\n","        transformed_sql['union']['sql'] = query\n","        _transform(components, transformed_sql, col_set, table_names, schema)\n","        _transform(components, transformed_sql['union'], col_set, table_names, schema)\n","    elif c_instance.id_c == 2:\n","        transformed_sql['except'] = dict()\n","        transformed_sql['except']['sql'] = query\n","        _transform(components, transformed_sql, col_set, table_names, schema)\n","        _transform(components, transformed_sql['except'], col_set, table_names, schema)\n","    else:\n","        _transform(components, transformed_sql, col_set, table_names, schema)\n","\n","    parse_result = to_str(transformed_sql, 1, schema)\n","\n","    parse_result = parse_result.replace('\\t', '')\n","    return [parse_result]\n","\n","def col_to_str(agg, col, tab, table_names, N=1):\n","    _col = col.replace(' ', '_')\n","    if agg == 'none':\n","        if tab not in table_names:\n","            table_names[tab] = 'T' + str(len(table_names) + N)\n","        table_alias = table_names[tab]\n","        if col == '*':\n","            return '*'\n","        return '%s.%s' % (table_alias, _col)\n","    else:\n","        if col == '*':\n","            if tab is not None and tab not in table_names:\n","                table_names[tab] = 'T' + str(len(table_names) + N)\n","            return '%s(%s)' % (agg, _col)\n","        else:\n","            if tab not in table_names:\n","                table_names[tab] = 'T' + str(len(table_names) + N)\n","            table_alias = table_names[tab]\n","            return '%s(%s.%s)' % (agg, table_alias, _col)\n","\n","\n","def infer_from_clause(table_names, schema, columns):\n","    tables = list(table_names.keys())\n","    # print(table_names)\n","    start_table = None\n","    end_table = None\n","    join_clause = list()\n","    if len(tables) == 1:\n","        join_clause.append((tables[0], table_names[tables[0]]))\n","    elif len(tables) == 2:\n","        use_graph = True\n","        # print(schema['graph'].vertices)\n","        for t in tables:\n","            if t not in schema['graph'].vertices:\n","                use_graph = False\n","                break\n","        if use_graph:\n","            start_table = tables[0]\n","            end_table = tables[1]\n","            _tables = list(schema['graph'].dijkstra(tables[0], tables[1]))\n","            # print('Two tables: ', _tables)\n","            max_key = 1\n","            for t, k in table_names.items():\n","                _k = int(k[1:])\n","                if _k > max_key:\n","                    max_key = _k\n","            for t in _tables:\n","                if t not in table_names:\n","                    table_names[t] = 'T' + str(max_key + 1)\n","                    max_key += 1\n","                join_clause.append((t, table_names[t],))\n","        else:\n","            join_clause = list()\n","            for t in tables:\n","                join_clause.append((t, table_names[t],))\n","    else:\n","        # > 2\n","        # print('More than 2 table')\n","        for t in tables:\n","            join_clause.append((t, table_names[t],))\n","\n","    if len(join_clause) >= 3:\n","        star_table = None\n","        for agg, col, tab in columns:\n","            if col == '*':\n","                star_table = tab\n","                break\n","        if star_table is not None:\n","            star_table_count = 0\n","            for agg, col, tab in columns:\n","                if tab == star_table and col != '*':\n","                    star_table_count += 1\n","            if star_table_count == 0 and ((end_table is None or end_table == star_table) or (start_table is None or start_table == star_table)):\n","                # Remove the table the rest tables still can join without star_table\n","                new_join_clause = list()\n","                for t in join_clause:\n","                    if t[0] != star_table:\n","                        new_join_clause.append(t)\n","                join_clause = new_join_clause\n","\n","    join_clause = ' JOIN '.join(['%s AS %s' % (jc[0], jc[1]) for jc in join_clause])\n","    return 'FROM ' + join_clause\n","\n","def replace_col_with_original_col(query, col, current_table):\n","    # print(query, col)\n","    if query == '*':\n","        return query\n","\n","    cur_table = col\n","    cur_col = query\n","    single_final_col = None\n","    # print(query, col)\n","    for col_ind, col_name in enumerate(current_table['schema_content_clean']):\n","        if col_name == cur_col:\n","            assert cur_table in current_table['table_names']\n","            if current_table['table_names'][current_table['col_table'][col_ind]] == cur_table:\n","                single_final_col = current_table['column_names_original'][col_ind][1]\n","                break\n","\n","    assert single_final_col\n","    # if query != single_final_col:\n","    #     print(query, single_final_col)\n","    return single_final_col\n","\n","\n","def build_graph(schema):\n","    relations = list()\n","    foreign_keys = schema['foreign_keys']\n","    for (fkey, pkey) in foreign_keys:\n","        fkey_table = schema['table_names_original'][schema['column_names'][fkey][0]]\n","        pkey_table = schema['table_names_original'][schema['column_names'][pkey][0]]\n","        relations.append((fkey_table, pkey_table))\n","        relations.append((pkey_table, fkey_table))\n","    return Graph(relations)\n","\n","\n","def preprocess_schema(schema):\n","    tmp_col = []\n","    for cc in [x[1] for x in schema['column_names']]:\n","        if cc not in tmp_col:\n","            tmp_col.append(cc)\n","    schema['col_set'] = tmp_col\n","    # print table\n","    schema['schema_content'] = [col[1] for col in schema['column_names']]\n","    schema['col_table'] = [col[0] for col in schema['column_names']]\n","    graph = build_graph(schema)\n","    schema['graph'] = graph\n","\n","\n","\n","\n","def to_str(sql_json, N_T, schema, pre_table_names=None):\n","    all_columns = list()\n","    select_clause = list()\n","    table_names = dict()\n","    current_table = schema\n","    for (agg, col, tab) in sql_json['select']:\n","        all_columns.append((agg, col, tab))\n","        select_clause.append(col_to_str(agg, col, tab, table_names, N_T))\n","    select_clause_str = 'SELECT ' + ', '.join(select_clause).strip()\n","\n","    sup_clause = ''\n","    order_clause = ''\n","    direction_map = {\"des\": 'DESC', 'asc': 'ASC'}\n","\n","    if 'sup' in sql_json:\n","        (direction, agg, col, tab,) = sql_json['sup']\n","        all_columns.append((agg, col, tab))\n","        subject = col_to_str(agg, col, tab, table_names, N_T)\n","        sup_clause = ('ORDER BY %s %s LIMIT 1' % (subject, direction_map[direction])).strip()\n","    elif 'order' in sql_json:\n","        (direction, agg, col, tab,) = sql_json['order']\n","        all_columns.append((agg, col, tab))\n","        subject = col_to_str(agg, col, tab, table_names, N_T)\n","        order_clause = ('ORDER BY %s %s' % (subject, direction_map[direction])).strip()\n","\n","    has_group_by = False\n","    where_clause = ''\n","    have_clause = ''\n","    if 'where' in sql_json:\n","        conjunctions = list()\n","        filters = list()\n","        # print(sql_json['where'])\n","        for f in sql_json['where']:\n","            if isinstance(f, str):\n","                conjunctions.append(f)\n","            else:\n","                op, agg, col, tab, value = f\n","                if value:\n","                    value['sql'] = sql_json['sql']\n","                all_columns.append((agg, col, tab))\n","                subject = col_to_str(agg, col, tab, table_names, N_T)\n","                if value is None:\n","                    where_value = '1'\n","                    if op == 'between':\n","                        where_value = '1 AND 2'\n","                    filters.append('%s %s %s' % (subject, op, where_value))\n","                else:\n","                    if op == 'in' and len(value['select']) == 1 and value['select'][0][0] == 'none' \\\n","                            and 'where' not in value and 'order' not in value and 'sup' not in value:\n","                            # and value['select'][0][2] not in table_names:\n","                        if value['select'][0][2] not in table_names:\n","                            table_names[value['select'][0][2]] = 'T' + str(len(table_names) + N_T)\n","                        filters.append(None)\n","\n","                    else:\n","                        filters.append('%s %s %s' % (subject, op, '(' + to_str(value, len(table_names) + 1, schema) + ')'))\n","                if len(conjunctions):\n","                    filters.append(conjunctions.pop())\n","\n","        aggs = ['count(', 'avg(', 'min(', 'max(', 'sum(']\n","        having_filters = list()\n","        idx = 0\n","        while idx < len(filters):\n","            _filter = filters[idx]\n","            if _filter is None:\n","                idx += 1\n","                continue\n","            for agg in aggs:\n","                if _filter.startswith(agg):\n","                    having_filters.append(_filter)\n","                    filters.pop(idx)\n","                    # print(filters)\n","                    if 0 < idx and (filters[idx - 1] in ['and', 'or']):\n","                        filters.pop(idx - 1)\n","                        # print(filters)\n","                    break\n","            else:\n","                idx += 1\n","        if len(having_filters) > 0:\n","            have_clause = 'HAVING ' + ' '.join(having_filters).strip()\n","        if len(filters) > 0:\n","            # print(filters)\n","            filters = [_f for _f in filters if _f is not None]\n","            conjun_num = 0\n","            filter_num = 0\n","            for _f in filters:\n","                if _f in ['or', 'and']:\n","                    conjun_num += 1\n","                else:\n","                    filter_num += 1\n","            if conjun_num > 0 and filter_num != (conjun_num + 1):\n","                # assert 'and' in filters\n","                idx = 0\n","                while idx < len(filters):\n","                    if filters[idx] == 'and':\n","                        if idx - 1 == 0:\n","                            filters.pop(idx)\n","                            break\n","                        if filters[idx - 1] in ['and', 'or']:\n","                            filters.pop(idx)\n","                            break\n","                        if idx + 1 >= len(filters) - 1:\n","                            filters.pop(idx)\n","                            break\n","                        if filters[idx + 1] in ['and', 'or']:\n","                            filters.pop(idx)\n","                            break\n","                    idx += 1\n","            if len(filters) > 0:\n","                where_clause = 'WHERE ' + ' '.join(filters).strip()\n","                where_clause = where_clause.replace('not_in', 'NOT IN')\n","            else:\n","                where_clause = ''\n","\n","        if len(having_filters) > 0:\n","            has_group_by = True\n","\n","    for agg in ['count(', 'avg(', 'min(', 'max(', 'sum(']:\n","        if (len(sql_json['select']) > 1 and agg in select_clause_str)\\\n","                or agg in sup_clause or agg in order_clause:\n","            has_group_by = True\n","            break\n","\n","    group_by_clause = ''\n","    if has_group_by:\n","        if len(table_names) == 1:\n","            # check none agg\n","            is_agg_flag = False\n","            for (agg, col, tab) in sql_json['select']:\n","\n","                if agg == 'none':\n","                    group_by_clause = 'GROUP BY ' + col_to_str(agg, col, tab, table_names, N_T)\n","                else:\n","                    is_agg_flag = True\n","\n","            if is_agg_flag is False and len(group_by_clause) > 5:\n","                group_by_clause = \"GROUP BY\"\n","                for (agg, col, tab) in sql_json['select']:\n","                    group_by_clause = group_by_clause + ' ' + col_to_str(agg, col, tab, table_names, N_T)\n","\n","            if len(group_by_clause) < 5:\n","                if 'count(*)' in select_clause_str:\n","                    current_table = schema\n","                    for primary in current_table['primary_keys']:\n","                        if current_table['table_names'][current_table['col_table'][primary]] in table_names :\n","                            group_by_clause = 'GROUP BY ' + col_to_str('none', current_table['schema_content'][primary],\n","                                                                       current_table['table_names'][\n","                                                                           current_table['col_table'][primary]],\n","                                                                       table_names, N_T)\n","        else:\n","            # if only one select\n","            if len(sql_json['select']) == 1:\n","                agg, col, tab = sql_json['select'][0]\n","                non_lists = [tab]\n","                fix_flag = False\n","                # add tab from other part\n","                for key, value in table_names.items():\n","                    if key not in non_lists:\n","                        non_lists.append(key)\n","\n","                a = non_lists[0]\n","                b = None\n","                for non in non_lists:\n","                    if a != non:\n","                        b = non\n","                if b:\n","                    for pair in current_table['foreign_keys']:\n","                        t1 = current_table['table_names'][current_table['col_table'][pair[0]]]\n","                        t2 = current_table['table_names'][current_table['col_table'][pair[1]]]\n","                        if t1 in [a, b] and t2 in [a, b]:\n","                            if pre_table_names and t1 not in pre_table_names:\n","                                assert t2 in pre_table_names\n","                                t1 = t2\n","                            group_by_clause = 'GROUP BY ' + col_to_str('none',\n","                                                                       current_table['schema_content'][pair[0]],\n","                                                                       t1,\n","                                                                       table_names, N_T)\n","                            fix_flag = True\n","                            break\n","\n","                if fix_flag is False:\n","                    agg, col, tab = sql_json['select'][0]\n","                    group_by_clause = 'GROUP BY ' + col_to_str(agg, col, tab, table_names, N_T)\n","\n","            else:\n","                # check if there are only one non agg\n","                non_agg, non_agg_count = None, 0\n","                non_lists = []\n","                for (agg, col, tab) in sql_json['select']:\n","                    if agg == 'none':\n","                        non_agg = (agg, col, tab)\n","                        non_lists.append(tab)\n","                        non_agg_count += 1\n","\n","                non_lists = list(set(non_lists))\n","                # print(non_lists)\n","                if non_agg_count == 1:\n","                    group_by_clause = 'GROUP BY ' + col_to_str(non_agg[0], non_agg[1], non_agg[2], table_names, N_T)\n","                elif non_agg:\n","                    find_flag = False\n","                    fix_flag = False\n","                    find_primary = None\n","                    if len(non_lists) <= 1:\n","                        for key, value in table_names.items():\n","                            if key not in non_lists:\n","                                non_lists.append(key)\n","                    if len(non_lists) > 1:\n","                        a = non_lists[0]\n","                        b = None\n","                        for non in non_lists:\n","                            if a != non:\n","                                b = non\n","                        if b:\n","                            for pair in current_table['foreign_keys']:\n","                                t1 = current_table['table_names'][current_table['col_table'][pair[0]]]\n","                                t2 = current_table['table_names'][current_table['col_table'][pair[1]]]\n","                                if t1 in [a, b] and t2 in [a, b]:\n","                                    if pre_table_names and t1 not in pre_table_names:\n","                                        assert  t2 in pre_table_names\n","                                        t1 = t2\n","                                    group_by_clause = 'GROUP BY ' + col_to_str('none',\n","                                                                               current_table['schema_content'][pair[0]],\n","                                                                               t1,\n","                                                                               table_names, N_T)\n","                                    fix_flag = True\n","                                    break\n","                    tab = non_agg[2]\n","                    assert tab in current_table['table_names']\n","\n","                    for primary in current_table['primary_keys']:\n","                        if current_table['table_names'][current_table['col_table'][primary]] == tab:\n","                            find_flag = True\n","                            find_primary = (current_table['schema_content'][primary], tab)\n","                    if fix_flag is False:\n","                        if find_flag is False:\n","                            # rely on count *\n","                            foreign = []\n","                            for pair in current_table['foreign_keys']:\n","                                if current_table['table_names'][current_table['col_table'][pair[0]]] == tab:\n","                                    foreign.append(pair[1])\n","                                if current_table['table_names'][current_table['col_table'][pair[1]]] == tab:\n","                                    foreign.append(pair[0])\n","\n","                            for pair in foreign:\n","                                if current_table['table_names'][current_table['col_table'][pair]] in table_names:\n","                                    group_by_clause = 'GROUP BY ' + col_to_str('none', current_table['schema_content'][pair],\n","                                                                                   current_table['table_names'][current_table['col_table'][pair]],\n","                                                                                   table_names, N_T)\n","                                    find_flag = True\n","                                    break\n","                            if find_flag is False:\n","                                for (agg, col, tab) in sql_json['select']:\n","                                    if 'id' in col.lower():\n","                                        group_by_clause = 'GROUP BY ' + col_to_str(agg, col, tab, table_names, N_T)\n","                                        break\n","                                if len(group_by_clause) > 5:\n","                                    pass\n","                                else:\n","                                    raise RuntimeError('fail to convert')\n","                        else:\n","                            group_by_clause = 'GROUP BY ' + col_to_str('none', find_primary[0],\n","                                                                       find_primary[1],\n","                                                                       table_names, N_T)\n","    intersect_clause = ''\n","    if 'intersect' in sql_json:\n","        sql_json['intersect']['sql'] = sql_json['sql']\n","        intersect_clause = 'INTERSECT ' + to_str(sql_json['intersect'], len(table_names) + 1, schema, table_names)\n","    union_clause = ''\n","    if 'union' in sql_json:\n","        sql_json['union']['sql'] = sql_json['sql']\n","        union_clause = 'UNION ' + to_str(sql_json['union'], len(table_names) + 1, schema, table_names)\n","    except_clause = ''\n","    if 'except' in sql_json:\n","        sql_json['except']['sql'] = sql_json['sql']\n","        except_clause = 'EXCEPT ' + to_str(sql_json['except'], len(table_names) + 1, schema, table_names)\n","\n","    # print(current_table['table_names_original'])\n","    table_names_replace = {}\n","    for a, b in zip(current_table['table_names_original'], current_table['table_names']):\n","        table_names_replace[b] = a\n","    new_table_names = {}\n","    for key, value in table_names.items():\n","        if key is None:\n","            continue\n","        new_table_names[table_names_replace[key]] = value\n","    from_clause = infer_from_clause(new_table_names, schema, all_columns).strip()\n","\n","    sql = ' '.join([select_clause_str, from_clause, where_clause, group_by_clause, have_clause, sup_clause, order_clause,\n","                    intersect_clause, union_clause, except_clause])\n","\n","    return sql\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"GzjEaf6DuYSc","metadata":{"id":"GzjEaf6DuYSc"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"mQd7KqbTuel_","metadata":{"id":"mQd7KqbTuel_"},"outputs":[],"source":["data_df = pd.read_json(\"./data/dev.json\")\n","df = pd.DataFrame(data_df)"]},{"cell_type":"code","execution_count":null,"id":"7dZWOMv_vFWt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1673170563429,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"7dZWOMv_vFWt","outputId":"52c3af4b-f62c-4785-b0d4-eb74ce211fd3"},"outputs":[{"data":{"text/plain":["1032"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":null,"id":"df8d75b8","metadata":{"id":"df8d75b8"},"outputs":[],"source":["class args:\n","    data_path = './data'\n","    input_path = './data/predict_lf_0.75_sketch_dev_1032.json'\n","    output_path = './data/predict_sql_0.75_sketch_dev_1032.json'`"]},{"cell_type":"code","execution_count":null,"id":"57b9c779","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1452,"status":"ok","timestamp":1673169942568,"user":{"displayName":"Sindhuja S","userId":"00745991774938856916"},"user_tz":-330},"id":"57b9c779","outputId":"baed46d1-ab6e-4304-dc3f-a8b665fbcd06"},"outputs":[{"name":"stdout","output_type":"stream","text":["1030 0\n"]}],"source":["# loading dataSets\n","datas, schemas = load_dataSets(args)\n","alter_not_in(datas, schemas=schemas)\n","alter_inter(datas)\n","alter_column0(datas)\n","\n","index = range(len(datas))\n","count = 0\n","exception_count = 0\n","with open(args.output_path, 'w', encoding='utf8') as d, open('gold.txt', 'w', encoding='utf8') as g:\n","    for i in index:\n","        try:\n","            result = transform(datas[i], schemas[datas[i]['db_id']])\n","            d.write(result[0] + '\\n')\n","            g.write(\"%s\\t%s\\t%s\\n\" % (datas[i]['query'], datas[i][\"db_id\"], datas[i][\"question\"]))\n","            count += 1\n","        except Exception as e:\n","            result = transform(datas[i], schemas[datas[i]['db_id']], origin='Root1(3) Root(5) Sel(0) N(0) A(3) C(0) T(0)')\n","            exception_count += 1\n","            d.write(result[0] + '\\n')\n","            g.write(\"%s\\t%s\\t%s\\n\" % (datas[i]['query'], datas[i][\"db_id\"], datas[i][\"question\"]))\n","            count += 1\n","            print(e)\n","            print('Exception')\n","            print(traceback.format_exc())\n","            print('===\\n\\n')\n","\n","print(count, exception_count)"]},{"cell_type":"code","execution_count":null,"id":"de1457ed","metadata":{"id":"de1457ed"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
